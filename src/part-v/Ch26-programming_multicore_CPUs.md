# 多核 CPU 编程

![现代 CPU](../images/CPU.png)

*我们怎样编写在多核心 CPU 上运行更快的程序呢？这一切都与可变状态和并发有关*。

在过去（二十多年前），有两种并发模型。

- 共享状态的并发
- 消息传递的并发

编程界走了一条路（朝着共享状态）。Erlang 社区则走的是另一条路。(很少有其他语言循着 “消息传递的并发” 这条道路；这些别的语言有 [Oz](https://en.wikipedia.org/wiki/Oz_(programming_language)) 及 [Occam](https://en.wikipedia.org/wiki/Occam_(programming_language))）。


在消息传递的并发下，是没有共享状态的。所有计算在进程中完成，交换数据的 *唯一* 方式，是经由异步的消息传递。

*为何这很不错*？

共享状态的并发，涉及 “可变状态”（可被更改的内存）的这一概念 -- 诸如如 C、Java、C++ 等所有语言，都有着这种概念：有一种叫 *状态* 的东西，而我们可以改变他。

在咱们只有 *一个* 进程进行更改时，这不会有问题。


当咱们有正共用并修改 *同一* 内存的多个进程时，咱们就会后患无穷 -- 疯狂就在这里。

> **知识点**：
>
> [a receipe for disaster, 后患无穷](https://www.bbc.co.uk/learningenglish/chinese/features/authentic-real-english/ep-160405)

要防止共享内存的同时修改，我们就要使用某种加锁机制。咱们可以把这叫做互斥锁、同步方法或其他任何东西，但他仍是把锁。

当程序在临界区（当其持有锁）崩溃时，就会导致灾难。所有其他程序都不知道要做什么。当程序破坏了处于共享状态的内存时，灾难也将发生。其他程序将不知道要做什么。


程序员怎么解决这些问题呢？困难重重。在单核处理器上，他们的程序可能恰好工作了 -- 但在多核处理器上......就是灾难。

对此，有一些不同解决方案（事务内存可能是最好的），但这些充其量也就是些 “蹩脚货”。最糟糕的是，它们简直就是噩梦。

*Erlang 没有可变数据结构*（这也不全对，但也足够正确）。

- 没有可变数据结构 == 没有锁；
- 没有可变数据结构 == 易于并行化。

我们怎么做到并行化？很简单。程序员会把问题解法，分解成若干并行进程。

这种编程风格有自己的术语；他被叫做 *面向并发的编程*。


## Erlang 程序员的好消息


好消息是：咱们的 Erlang 程序在 *n* 个核心的处理器上，可能会以 `n` 倍快速度运行 -- *无需对程序的任何修改*。

但咱们必须遵循一套简单规则。

若咱们希望咱们的应用，在多核 CPU 上运行更快，咱们就必须确保其有着大量互不干扰的进程，并且咱们的程序中，没有顺序（代码）瓶颈。

当咱们把咱们的代码，写成了一大堆顺序代码，并从未使用 `spawn` 创建一个并行进程，那么咱们的程序，就可能不会更快。


请勿绝望。即使咱们的程序一开始是个巨大的顺序程序，对程序的几个简单改动，就将使其并行化。

在这一章中，我们将讨论以下主题：

- 我们必须完成哪些事情，使咱们的程序在多核 CPU 上高效运行；
- 怎样并行化某个顺序程序；
- 顺序化瓶颈问题；
- 如何避免一些副作用。

在我们完成上述主题后，我们将研究一个更复杂问题中所涉及的一些设计问题。我们将实现一个名为 `mapreduce` 的高阶函数，并展示他怎样用于并行化计算。 `mapreduce` 是谷歌开发的一个，用于在处理元素集上执行并行计算的抽象概念。

> **知识点**：
>
> - sets of processing elements

## 怎样令到程序在多核心 CPU 上高效运行


要高效运行，我们必须完成以下几点：

- 要使用大量进程；
- 要避免一些副作用；
- 要避免顺序化的一些瓶颈；
- 要编写 “小消息，大计算” 的代码。


当我们完成全部这些要求时，我们的 Erlang 程序，就应会在多核心 CPU 上高效运行。


> **我们为何应关注多核心 CPU**？
>
> 咱们可能想知道，这大惊小怪是为啥。我们真的有必要费心将程序并行化，使其能在多核心上运行吗？答案是肯定的。如今，带有超线程的四核已经司空见惯。智能手机也有四核心。就连我那低端的 MacBook Air，也有带超线程的双核心，而我的台式机，则有带超线程的八核心。
>
> 构造一个在双核心机器上以两倍的速度运行的成型，并不那么令人兴奋（但确实有点令人兴奋）。但我们不要自欺欺人。双核心处理器的时钟速度，比单核心 CPU 慢，因此性能的收益可能很小。
>
> 现在，虽然两倍提升还不能让我（作者）兴奋，但十倍就会，而一百倍就真的非常非常让人兴奋了。现代处理器如此之快，一个核心可运行 4 个超线程，那么一个 32 核心的 CPU，就可以提供 128 个线程使用。这意味着，百倍的速度指日可待。
>
> 一个一百的系数，确实让我（作者）兴奋。
>
> 我们要做的就是，写下代码。


### 使用大量线程

这点很重要 -- 我们必须让 CPU 忙起来。所有 CPU 都应该一直处于忙碌状态。要做到这一点，最简单方法就是要有大量进程。

在我（作者）讲到大量进程进程时，我指的是与 CPU 数量相关的大量。当我们有很多进程时，那么我们将无需担心让 CPU 忙碌了。这表现为一种纯粹的统计效应。当我们有着少量的进程时，他们可能不小心占用一个 CPU；当我们有着很大数量的进程时，这种效应似乎就消失了。当我们想要咱们的程序不过时，我们就应该考虑到，即使现今的芯片可能只有少量 CPU，但将来我们可能就会有每个芯片的成千上万个 CPU。


这些进程的工作量最好相近。编写出其中一个进程完成很多工作，而别的进程完成很少工作的程序，是个糟糕的主意。


在许多应用中，我们都 “免费” 获得了大量进程。当应用 “本质上是并行的” 时，那么我们就不必担心，并行化代码的问题。例如，当我们正编写某个管理数万个并发连接的消息系统时，那么我们会获得这数万个连接中的并发性；而处理某单个连接的代码，则将不必担心并发性问题。


### 避免副作用





## 并行序列代码

